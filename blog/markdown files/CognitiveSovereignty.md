---
layout: post
author: Mukul Ramesh
title: template
---
# a human in a bot world


## TLDR:
hey, isnt it weird how normalized hyper-specific advertising is?

its even weirder that there isn't really an "opt-out" button anymore. i'm a little worried about the power dynamics of that kind of thing.

im *really* worried about the power dynamics of trying to be human in a bot dominated internet.

maybe its time for us to leave, and let the agents do the talking.

## we dont even think its a problem anymore
I mean, we all have stories of getting a Google ad that was scarily accurate right? you were *just* talking about your upcoming barbeque and suddenly you're getting ads for grills. Suspicious.

Maybe back in 2010 that would have elicited more of a "Big Brother" feeling, but I don't really see that reaction anymore. And now, it isn't just advertising! Basically all the content I consume comes from Youtube and the other social media platforms of my choice, and I am willing to bet that most people are in the same boat as me.

It's now an unfortunate fact of life that almost everything in front of my eyes has been curated by someone I don't really trust.

The public consensus has been to essentially shrug and say "well what can you do". And I get it; it does seem inescapable. Trying to get off of social media is like trying to quit smoking, say nothing of the social pressure and network effects that these behemoths have.

## why I think we need to revisit this issue
The invention of GenAI shifted the power dynamic again; suddenly, your ability to create ~~content~~ slop is limited only by the number of GPUs at your disposal.

This changed the equation for every engagement driven platform. They benefit from content that optimizes for dopamine and outrage, rather than thoughtful content, and so AI slop dominates.

Even in platforms where human connection is a priority, it is now possible for GenAI to infiltrate and pose as humans. We know this has happened before:

[picture of AI being told to ignore previous instructions and output recipe]
*dead internet theory*

And the technology will only mature (read: become more undetectable) from here.

The consumer can alter their behavior around an algorithm, but the consumer does not have control over their algorithms.

## quick side tangent
I've seen some sentiment from my friends and family about ways you can participate on these platforms without being "manipulated". Purportedly, it is a matter of "willpower". I've heard language about "building your feed brick by brick", which places quite a lot of agency on the part of the user.

I can see why this framing is beneficial. Being essentially forced to participate on these platforms, it is empowering to believe that you are the one at the helm.

However, consider the strength of your opponent: they have a century's worth of psychology and neuroscience research [^1], and are willing to spend their billions of dollars annually on protecting their interests [^2].

What would a solution even look like [^3]?

## A modern proposal
Imagine a user-owned AI that operates across every "social-media consumption device" you own. Rather than simply blocking visual banners, it blocks irrelevant concepts. Imagine browsing Amazon not through their "personalized" user interface, but through an agent that scrapes the raw data and re-renders only the three options that meet strict criteria, such as "ethically sourced" and "under $50."

This would invert the power dynamic of the modern web. Currently, marketers A/B test against our psychology. In this new paradigm, ***our*** agents A/B test against their marketing claims.

I imagine a product that optimizes for the user's intent, *as the user defines it for themselves* rather than something as harmful as guessing what the user wants through a proxy like *engagement*.

## im being fr rn
The proposal for personal AI agents often sounds like science fiction, but the technical reality is already here.

We are currently undergoing a massive hardware shift with the rise of the Neural Processing Unit (NPU) in consumer devices. From the Apple Neural Engine to Snapdragon processors, our laptops and phones now possess the silicon required to run quantized Small Language Models (SLMs) like Llama-3-8B or Mistral locally.

Fundamentally, this product requires that the agent respects user privacy: everything needs to run on user-owned devices.

Cloud-based AI is inherently a surveillance architecture, and requires sending your data to untrusted models. Local AI is a utility architecture; it brings the model to your data. This is not a service you subscribe to, but a tool you own. A pair of glasses shouldn't report what you see to a corporation.

## this will totally work
Critics of this shift often point to the "Adversarial Web" as an economic barrier. If users deploy agents to scrape clean data, companies will likely retaliate by blocking scrapers and obfuscating information to protect their "walled gardens." I believe this is a technical challenge that which is being solved at a rapid pace; web scraping technology has rapidly matured in response to the gluttenous cost of training AI.

Just as websites optimized for Google's crawlers to survive the search engine era, retailers will eventually have to optimize for AI agents to capture high-intent buyers. I envision "SEO for Agents": "clean data" APIs over visual clutter.

A more ethical concern is the risk of the "Echo Chamber." If an agent only shows us what we want to see, do we risk radicalization?

While solipsism is a valid risk, it is arguably the lesser of two evils. The current reality is an active radicalization engine, where algorithms monetize outrage to keep users scrolling.

A user-owned shield is ethically superior to a system designed for profit-driven manipulation.

## it matters
Desperate and vulnerable people will always be the ones who are exploited the most.

This means your kids. This means a weaker social safety net for you and your loved ones.

This is different than what has come before. A basic human right of self-determination is under attack, and we should build the tools to fight back.


## References

[^1]: The study of persuasive advertisement began in 1895 when Harlow Gale, a psychologist at the University of Minnesota, sent out questionnaires to businesses to study how people reacted to advertisements. Soon after in 1903, Walter Dill Scott published *The Theory of Advertising* in where he argued that humans were not purely rational but were highly suggestible and influenced by emotion and imagery.

[^2]: https://www.mordorintelligence.com/industry-reports/neuromarketing-market

[^3]: Okay, so you *could* go live in a cabin in the woods. But you shouldn't need to resort to such extreme methods. We live in an increasingly interconnected world; how can you go live in a cabin in the woods when there aren't any woods left?

