---
layout: post
author: Mukul Ramesh
title: template
---
# Cognitive Sovereignty and You


## TLDR:
Everything's trying to manipulate you and you don't have the tools to stop them. But we can make them.

## What I mean by "Everything's trying to get you"
Okay, "everything" might be an exaggeration, but it's not much of one:

There are many people out there whose motives differ from your own. For some of these people, you could be a source of value, and so these people may want you to act against your best interest.

For example, take the typical American company. Their primary goal is to increase value for their shareholders. Some of the actions they take may be beneficial for you (innovation to improve their product) but not all (like funding misinformation about the adverse effects of their product).

A company will operate with your personal best interests *if and only if* the company believes doing so is necessary to maximize profits. So, not likely.

This is the first basic assumption in this essay.

## What I mean by "you don't have the tools to stop them"

The modern world is dominated by a few hegemonies. This fact is important because when power is consolidated, it is more difficult to get out from under it. You are no longer protecting your mind from a human; you must protect it from entities with a century's worth of psychology and neuroscience research [^1], and who are willing to spend billions of dollars annually [^2].

They are better at manipulating you then you are at fighting their manipulations. "Education as innoculation" simply isn't good enough [^3]. Even the "tools" we have are co-opted to serve outside interests: bot farms, paid reviews, and aggressive SEO gaming have rendered public signals noisy and often entirely fabricated. In fact, I have not learned of a tool or strategy that is 100% effective; that is, a tool that guarantees your perception of reality to be  "untampered" [^4].

This is the second basic assumption of this essay.

## It gets worse

So far, this essay could ostensibly be only about advertising.

About 10 to 15 years ago, the power dynamic between media and the world radically shifted. We shifted from a "one-to-many" *broadcast* world, where a few TV channels spoke to millions, to a "many-to-many" *algorithmic* world where millions of entities compete for the attention of billions.

Very recently, the power dynamic shifted again, with the invention of GenAI; suddenly, your ability to create ~~content~~ slop is limited only by the number of GPUs at your disposal.

This changed the equation for every engagement driven platform. They benefit from content that optimizes for dopamine and outrage, rather than thoughtful content, and so AI slop dominates.

Even in platforms where human connection is a priority, it is now possible for GenAI to infiltrate and pose as humans. We know this has happened before:

[picture of AI being told to ignore previous instructions and output recipe]
*dead internet theory*

and the technology will only mature (read: become more undetectable) from here.

The consumer can alter their behavior around an algorithm, but the consumer does not have control over their algorithms.

What if we could change that?

## A modern proposal
Imagine a user-owned AI that operates across every "social-media consumption device" you own. Rather than simply blocking visual banners, it blocks irrelevant concepts. Imagine browsing Amazon not through their "personalized" user interface, but through an agent that scrapes the raw data and re-renders only the three options that meet strict criteria, such as "ethically sourced" and "under $50."

This would invert the power dynamic of the modern web. Currently, marketers A/B test against our psychology. In this new paradigm, ***our*** agents A/B test against their marketing claims.

I imagine a product that optimizes for the user's intent, *as the user defines it for themselves* rather than something as harmful as guessing what the user wants through a proxy like *engagement*.

## im being fr rn
The proposal for personal AI agents often sounds like science fiction, but the technical reality is already here.

We are currently undergoing a massive hardware shift with the rise of the Neural Processing Unit (NPU) in consumer devices. From the Apple Neural Engine to Snapdragon processors, our laptops and phones now possess the silicon required to run quantized Small Language Models (SLMs) like Llama-3-8B or Mistral locally.

Fundamentally, this product requires that the agent respects user privacy: everything needs to run on user-owned devices.

Cloud-based AI is inherently a surveillance architecture, and requires sending your data to untrusted models. Local AI is a utility architecture; it brings the model to your data. This is not a service you subscribe to, but a tool you own. A pair of glasses shouldn't report what you see to a corporation.

## this will totally work
Critics of this shift often point to the "Adversarial Web" as an economic barrier. If users deploy agents to scrape clean data, companies will likely retaliate by blocking scrapers and obfuscating information to protect their "walled gardens." I believe this is a technical challenge that which is being solved at a rapid pace; web scraping technology has rapidly matured in response to the gluttenous cost of training AI.

Just as websites optimized for Google's crawlers to survive the search engine era, retailers will eventually have to optimize for AI agents to capture high-intent buyers. I envision "SEO for Agents": "clean data" APIs over visual clutter.

A more ethical concern is the risk of the "Echo Chamber." If an agent only shows us what we want to see, do we risk radicalization?

While solipsism is a valid risk, it is arguably the lesser of two evils. The current reality is an active radicalization engine, where algorithms monetize outrage to keep users scrolling.

A user-owned shield is ethically superior to a system designed for profit-driven manipulation.

## it matters
Desperate and vulnerable people will always be the ones who are exploited the most.

This means your kids. This means a weaker social safety net for you and your loved ones.

This is different than what has come before. A basic human right of self-determination is under attack, and we should build the tools to fight back.


## References

[^1]: The study of persuasive advertisement began in 1895 when Harlow Gale, a psychologist at the University of Minnesota, sent out questionnaires to businesses to study how people reacted to advertisements. Soon after in 1903, Walter Dill Scott published *The Theory of Advertising* in where he argued that humans were not purely rational but were highly suggestible and influenced by emotion and imagery.

[^2]: https://www.mordorintelligence.com/industry-reports/neuromarketing-market

[^3]: https://www.emergentmind.com/topics/dark-pattern-effectiveness

[^4]: Okay, so you *could* go live in a cabin in the woods. But (1) you won't and (2) you shouldn't need to resort to such extreme methods just to reclaim the sanctity of your own mind. We live in an interconnected world; that is what makes it livable. The option to leave the world behind presupposes a not-unsubstantial level of wealth. How can you go live in a cabin in the woods when there aren't any woods left? How much will the untainted world be worth then? It isn't an option for most of us.

